# ğŸ“š Advanced Recommender System

<p align="center">
  <img src="https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=for-the-badge&logo=PyTorch&logoColor=white" alt="PyTorch">
  <img src="https://img.shields.io/badge/Hugging%20Face-FFD21E?style=for-the-badgelogo=huggingface&logoColor=000" alt="Hugging Face Transformers">
  <img src="https://img.shields.io/badge/scikit--learn-%23F7931E.svg?style=for-the-badge&logo=scikit-learn&logoColor=white" alt="scikit-learn">
  <img src="https://img.shields.io/badge/Jupyter-F37626.svg?&style=for-the-badge&logo=Jupyter&logoColor=white" alt="Jupyter Notebook">
</p>
<p align="center">

Welcome to the **Advanced Recommender Systems**!

---

## ğŸš€ Project Overview

Our goal is to create a comprehensive platform that excels in retrieving, classifying, ranking, and recommending documents tailored to user preferences. The pipeline of the project follows these key stages:

1. **Data Collection & Preprocessing**: 
   - ğŸ“¥ **Data Collection**: Gather academic paper data.
   - ğŸ”§ **Preprocessing**: Prepare data for indexing.

2. **Indexing & Retrieval Infrastructure**: 
   - ğŸ—‚ï¸ **Indexing**: Develop an indexing system.
   - âœï¸ **Spell Correction**: Integrate spell correction mechanisms.
   - ğŸ“Š **Vector Space Models**: Apply models for accurate search ranking.

3. **Machine Learning & Clustering**: 
   - ğŸ¤– **Machine Learning**: Implement classification algorithms.
   - ğŸ§© **Clustering**: Organize documents into clusters.

4. **Web Crawling & Personalized Search**: 
   - ğŸŒ **Web Crawling**: Collect additional data from the web.
   - ğŸ” **Personalized Search**: Develop advanced search and recommendation features.

5. **Evaluation & Optimization**: 
   - ğŸ“ˆ **Evaluation**: Assess system performance using metrics.
   - ğŸ”§ **Optimization**: Refine and improve system effectiveness.

---

## ğŸ—ï¸ Phase 1: Data Acquisition and Indexing Infrastructure

Phase 1 focuses on laying the foundation for a robust information retrieval system by establishing an efficient data processing and indexing infrastructure.

### Datasets

- **Dataset**: Scientific articles from [Semantic Scholar](https://www.semanticscholar.org/).
- **Dataset Category**: Artificial Intelligence & Bioinformatics

### Key Components

- **ğŸ“‚ Data Preprocessing & Preparation**: Structure academic papers for efficient retrieval.
- **ğŸ“š Positional Index Construction**: Create a positional index for precise document searches.
- **ğŸ”  Spell Correction Integration**: Integrate a bigram-based spell correction system.
- **ğŸ§® Vector Space Modeling**: Implement vector space models for effective document ranking:
  - **`ltn-lnn`**: Term frequency normalization model.
  - **`ltc-lnc`**: Term and document frequency adjustment model.
  - **`Okapi BM25`**: Probabilistic relevance ranking model.
- **ğŸ“ˆ Evaluation Metrics**: Assess system performance with metrics like MRR, Precision, Recall, F1 Score, MAP, and NDCG.

---

## ğŸ§¬ Phase 2: Machine Learning and Clustering for Document Retrieval

In Phase 2, we enhance retrieval capabilities through machine learning techniques, improving classification and clustering to refine the search system.

### Key Components

- **ğŸ“‚ Dataset**: Access the scientific articles dataset from [Kaggle](https://www.kaggle.com/datasets/spsayakpaul/arxiv-paper-abstracts?resource=download).
- **ğŸ“Š Naive Bayes Classification**: Implement a Naive Bayes classifier for document categorization.
- **ğŸ¤– Neural Network Classifier**: Develop a neural network classifier for improved accuracy.
- **ğŸ§  Large Language Models**: Fine-tune a pre-trained model for advanced classification.
- **ğŸ§® Hierarchical Clustering**: Apply hierarchical clustering for document organization.

---

## ğŸ› ï¸ Phase 3: Web Crawling, Link Analysis, and Personalized Search

Phase 3 centers on expanding the systemâ€™s capabilities with web crawling, link analysis, and advanced personalization features.

### Key Components

- **ğŸ•·ï¸ Web Crawling**: Deploy a web crawler to gather academic articles and related data.
- **ğŸ”— Link Analysis**: Utilize PageRank and HITS algorithms to determine article importance.
- **ğŸ“š Content-Based Recommendation**: Develop recommendations based on article content similarity.
- **ğŸ¤ Collaborative Filtering**: Recommend articles based on the preferences of similar users.
- **ğŸ§ª Evaluation of Recommender Systems**: Measure recommendation system performance using metrics like nDCG.

### Final Product

Upon completion of Phase 3, the Advanced Recommender Systems will be a comprehensive tool that excels in retrieving, organizing, ranking, and recommending academic papers tailored to users' research needs.

---

## ğŸ“ License

This project is licensed under the MIT License. For detailed information, please refer to the [LICENSE](LICENSE) file.

---

Thank you for your interest in the **Advanced Recommender Systems**! We hope this project serves as a valuable and engaging tool for your research and information retrieval needs. Happy exploring! ğŸš€
